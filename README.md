# LLM-for-MCQA-with-Enhanced-query-RAG
This repository implements a large language model (LLM) for answering multiple-choice questions (MCQA) using an enhanced Retrieval-Augmented Generation (RAG) approach. It improves accuracy by dynamically retrieving relevant information to support the modelâ€™s predictions on MCQ tasks.
